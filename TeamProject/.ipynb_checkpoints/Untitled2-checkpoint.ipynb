{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d89f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7b8e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 동영상 파일 경로\n",
    "input_file = \"/Users/yuna/Homework/IMG_3644.mov\"\n",
    "original = \"/Users/yuna/Homework/BrailleBlockOriginal.jpeg\"\n",
    "\n",
    "# 비디오 캡처 객체 생성\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "orig = cv2.imread(original, 1)\n",
    "\n",
    "# 영상의 너비와 높이 가져오기\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# original의 크기를 영상에 맞추기\n",
    "orig = cv2.resize(orig, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "#original를 numpy 배열로 변환\n",
    "orig = np.array(orig, dtype=np.uint8)\n",
    "\n",
    "#print(h, w)\n",
    "h, w, c = orig.shape\n",
    "\n",
    "# 특정 색상 범위 설정 (예: 노란색)\n",
    "lower_yellow = np.array([10, 20, 200])  # 범위의 하한값 (HSV 형식)\n",
    "upper_yellow = np.array([30, 80, 255])  # 범위의 상한값 (HSV 형식)\n",
    "\n",
    "# 사다리꼴 모양의 마스크 생성\n",
    "traMask = np.zeros((height, width), dtype=np.uint8)\n",
    "pts = np.array([[0, 1500], [width-100, 1500], [width-300, 500], [300, 600]], dtype=np.int32)\n",
    "cv2.fillPoly(traMask, [pts], 255)\n",
    "\n",
    "# 동영상의 프레임 레이트 가져오기\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_interval = int(fps * 10)  # 10초마다 프레임 추출cv2.fillPoly(traMask, [pts], 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e6dceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_mask(frame):\n",
    "    \"\"\"\n",
    "    입력된 프레임에 특정 색상 범위에 해당하는 마스크를 적용합니다.\n",
    "    \n",
    "    :param frame: 입력 프레임 (BGR 형식)\n",
    "    :param lower_color: 색상 범위의 하한값 (HSV 형식)\n",
    "    :param upper_color: 색상 범위의 상한값 (HSV 형식)\n",
    "    :return: 색상 마스크\n",
    "    \"\"\"\n",
    "    # 입력된 프레임을 HSV 형식으로 변환\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # 색상 범위에 해당하는 마스크 생성\n",
    "    mask = cv2.inRange(hsv_frame, lower_yellow, upper_yellow)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d35ea163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(frame):\n",
    "    \"\"\"\n",
    "    입력된 프레임에 히스토그램 평활화를 적용합니다.\n",
    "    \n",
    "    :param frame: 입력 프레임\n",
    "    :return: 히스토그램 평활화가 적용된 프레임\n",
    "    \"\"\"\n",
    "    # 입력 프레임을 그레이 스케일로 변환\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 히스토그램 평활화 적용\n",
    "    equalized_frame = cv2.equalizeHist(gray_frame)\n",
    "    \n",
    "    return equalized_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfcf1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_thresholding(mask):\n",
    "    \"\"\"\n",
    "    Otsu의 이진화를 적용하여 이진 마스크를 생성합니다.\n",
    "    \n",
    "    :param mask: 입력 마스크\n",
    "    :return: Otsu의 이진화가 적용된 마스크\n",
    "    \"\"\"\n",
    "    # Otsu의 이진화 적용\n",
    "    _, otsu_mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return otsu_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "baadbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_morphology(mask):\n",
    "    \"\"\"\n",
    "    입력된 마스크에 모폴로지 연산을 적용합니다.\n",
    "    \n",
    "    :param mask: 이진 마스크\n",
    "    :return: 모폴로지 연산이 적용된 마스크\n",
    "    \"\"\"\n",
    "    # 커널 생성\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    \n",
    "    # motphology 연산 적용 (잡음 제거)\n",
    "    result = cv2.dilate(mask, kernel, iterations=1)\n",
    "    result = cv2.dilate(result, kernel, iterations=1)\n",
    "    result = cv2.dilate(result, kernel, iterations=1)\n",
    "    #result = cv2.erode(result, kernel, iterations=1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64549047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    \"\"\"\n",
    "    주어진 프레임에 연결 성분 레이블링을 적용합니다.\n",
    "    \n",
    "    :param frame: 입력 프레임 (BGR 형식)\n",
    "    :return: 레이블링된 결과 프레임 (BGR 형식)\n",
    "    \"\"\"\n",
    "    # 그레이스케일로 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 이진화\n",
    "    _, binary_image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 연결 성분 레이블링\n",
    "    num_labels, labels_im = cv2.connectedComponents(binary_image)\n",
    "    \n",
    "    # 레이블링된 결과를 색상 이미지로 변환하여 시각화\n",
    "    label_hue = np.uint8(179 * labels_im / np.max(labels_im))\n",
    "    blank_ch = 255 * np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # HSV에서 BGR로 변환\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # 배경을 검정으로 변환\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    \n",
    "    return labeled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f3b19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def braille_detection(img):\n",
    "    # 마스크 적용\n",
    "    img = cv2.bitwise_and(img, img, mask=traMask)\n",
    "    \n",
    "    # 히스토그램 평활화 적용\n",
    "    equalized_frame = histogram_equalization(img)\n",
    "    \n",
    "    # 특정 색상 범위에 해당하는 마스크 적용\n",
    "    color_mask = yellow_mask(img)\n",
    "    \n",
    "    # Otsu의 이진화 적용\n",
    "    otsu_mask = otsu_thresholding(color_mask)\n",
    "    \n",
    "    # 마스크를 적용하여 특정 색상만 남기고 나머지는 가리기\n",
    "    masked_frame = cv2.bitwise_and(img, img, mask=otsu_mask)\n",
    "    \n",
    "    # 연결 성분 레이블링 적용\n",
    "    labeled_frame = process_frame(masked_frame)\n",
    "\n",
    "    # 모폴로지 연산 적용\n",
    "    new = apply_morphology(labeled_frame)\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82cdab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video():\n",
    "    # 동영상 프레임 처리\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        count += 1\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        new = braille_detection(frame)\n",
    "        #ori = braille_detection(orig)\n",
    "    \n",
    "        \"\"\"\n",
    "        if count % frame_interval == 0:\n",
    "            cv2.absdiff(new, ori)\n",
    "            dif = new - ori\n",
    "            np.array(dif)\n",
    "            total = np.sum(dif)\n",
    "            if (total > 300000):\n",
    "                print(\"Beep\")\n",
    "        \"\"\"\n",
    "    \n",
    "        # 결과 프레임 표시\n",
    "        cv2.imshow('Masked Equalized and Labeled Video', new)\n",
    "    \n",
    "        # 종료를 위한 키 입력 처리\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # 1ms 대기 (더 빠르게 재생)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d350673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/7h5phywx43537thdz_87qp3c0000gn/T/ipykernel_17905/1359856594.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  label_hue = np.uint8(179 * labels_im / np.max(labels_im))\n",
      "/var/folders/n9/7h5phywx43537thdz_87qp3c0000gn/T/ipykernel_17905/1359856594.py:18: RuntimeWarning: invalid value encountered in cast\n",
      "  label_hue = np.uint8(179 * labels_im / np.max(labels_im))\n"
     ]
    }
   ],
   "source": [
    "load_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce7253e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7819a0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "ori = braille_detection(orig)\n",
    "#new = braille_detection(frame)\n",
    "\n",
    "print(ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52d2161",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 8\u001b[0m orig \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(ori, cv2\u001b[38;5;241m.\u001b[39mCOLOR_HSV2RGB)\n\u001b[1;32m     10\u001b[0m show_img(orig)\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "def show_img(image, title=\"image\"):\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "orig = cv2.imread(, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "show_img(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7c51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a57f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
